{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Length vs. Semantic Noise Trade-off\n",
        "\n",
        "This notebook simulates prompts composed of informative and noisy tokens to study how latent drift depends on both total length and the semantic redundancy ratio $\\rho$. A concept vector is reconstructed from token embeddings that either align with the ground-truth manifold or introduce random noise. We evaluate mean squared error across different lengths and noise fractions and visualize the resulting heatmap.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "np.random.seed(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_error(seq_len: int, noise_ratio: float, dim: int = 64, trials: int = 200) -> float:\n",
        "    errors = []\n",
        "    for _ in range(trials):\n",
        "        concept = np.random.randn(dim)\n",
        "        concept /= np.linalg.norm(concept)\n",
        "        tokens = []\n",
        "        informative = int(round(seq_len * (1 - noise_ratio)))\n",
        "        noisy = seq_len - informative\n",
        "        if informative > 0:\n",
        "            info_tokens = concept + 0.1 * np.random.randn(informative, dim)\n",
        "            tokens.append(info_tokens)\n",
        "        if noisy > 0:\n",
        "            noise_tokens = np.random.randn(noisy, dim)\n",
        "            noise_tokens /= np.linalg.norm(noise_tokens, axis=1, keepdims=True)\n",
        "            tokens.append(noise_tokens)\n",
        "        prompt = np.vstack(tokens)\n",
        "        reconstruction = prompt.mean(axis=0)\n",
        "        reconstruction /= np.linalg.norm(reconstruction) + 1e-8\n",
        "        errors.append(np.linalg.norm(reconstruction - concept) ** 2)\n",
        "    return float(np.mean(errors))\n",
        "\n",
        "lengths = np.arange(2, 33)\n",
        "noise_levels = np.linspace(0, 0.8, 17)\n",
        "heatmap = np.zeros((len(noise_levels), len(lengths)))\n",
        "\n",
        "for i, noise in enumerate(noise_levels):\n",
        "    for j, length in enumerate(lengths):\n",
        "        heatmap[i, j] = simulate_error(length, noise)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "mesh = ax.imshow(\n",
        "    heatmap,\n",
        "    aspect=\"auto\",\n",
        "    origin=\"lower\",\n",
        "    extent=[lengths[0], lengths[-1], noise_levels[0], noise_levels[-1]],\n",
        "    cmap=\"viridis\",\n",
        ")\n",
        "ax.set_xlabel(\"Prompt length (tokens)\")\n",
        "ax.set_ylabel(\"Noise ratio (1 - œÅ)\")\n",
        "ax.set_title(\"Reconstruction error vs. length and semantic noise\")\n",
        "fig.colorbar(mesh, ax=ax, label=\"Mean squared error\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Increasing prompt length reduces error only when noise ratios remain low (high semantic redundancy). Once noise dominates, longer prompts plateau or worsen reconstruction, mirroring the hypothesis that unstructured repetition injects aliasing rather than usable redundancy.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
