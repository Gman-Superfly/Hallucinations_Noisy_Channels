{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chain-of-Thought as Redundant Channel Coding\n",
        "\n",
        "Chain-of-Thought (CoT) prompts encourage LLMs to emit intermediate reasoning steps. This notebook treats those steps as redundancy: extra symbols that can detect or correct semantic errors. We compare a direct transmission of an 8-bit answer through a binary symmetric channel (BSC) with a simple CoT-style scheme that repeats each bit three times (majority vote).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "np.random.seed(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transmit(bits, flip_prob, redundancy=1):\n",
        "    bits = np.array(bits)\n",
        "    repeated = np.repeat(bits, redundancy)\n",
        "    noise = np.random.rand(len(repeated)) < flip_prob\n",
        "    received = np.logical_xor(repeated, noise).astype(int)\n",
        "    if redundancy == 1:\n",
        "        decoded = received\n",
        "    else:\n",
        "        decoded = received.reshape(-1, redundancy).sum(axis=1) >= (redundancy // 2 + 1)\n",
        "        decoded = decoded.astype(int)\n",
        "    return decoded\n",
        "\n",
        "\n",
        "def simulate(flip_prob, trials=2000):\n",
        "    direct_errors = 0\n",
        "    cot_errors = 0\n",
        "    for _ in range(trials):\n",
        "        bits = np.random.randint(0, 2, size=8)\n",
        "        decoded_direct = transmit(bits, flip_prob, redundancy=1)\n",
        "        decoded_cot = transmit(bits, flip_prob, redundancy=3)\n",
        "        direct_errors += int(np.any(decoded_direct != bits))\n",
        "        cot_errors += int(np.any(decoded_cot != bits))\n",
        "    return direct_errors / trials, cot_errors / trials\n",
        "\n",
        "flip_probs = np.linspace(0.01, 0.3, 15)\n",
        "results = np.array([simulate(p) for p in flip_probs])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "ax.plot(flip_probs, results[:, 0], marker=\"o\", label=\"Direct decoding\")\n",
        "ax.plot(flip_probs, results[:, 1], marker=\"s\", label=\"CoT-style redundancy\")\n",
        "ax.set_xlabel(\"Bit flip probability (channel noise)\")\n",
        "ax.set_ylabel(\"Answer error rate\")\n",
        "ax.set_title(\"Chain-of-Thought as error-control coding\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Repeating each bit three times (analogous to emitting intermediate reasoning steps) dramatically lowers the probability that the final answer drifts, especially when channel noise exceeds 10%. In practice, CoT adds structured redundancy instead of literal bit repetition, but the effect—stabilizing trajectories via semantic parity checks—is the same.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
